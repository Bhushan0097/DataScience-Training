{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program : program\n",
      "Programs : program\n",
      "programer : program\n",
      "programming : program\n",
      "programers : program\n"
     ]
    }
   ],
   "source": [
    "#stemming of word\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "#choose some words to be stemmed\n",
    "words = ['Program','Programs','programer','programming','programers']\n",
    "\n",
    "for w in words:\n",
    "    print(w,':',ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alex : alex\n",
      "alexa : alexa\n",
      "alexsis : alexsi\n",
      " : \n",
      "alexander : alexand\n"
     ]
    }
   ],
   "source": [
    "words = ['Alex','alexa','alexsis','','alexander']\n",
    "\n",
    "for w in words:\n",
    "    print(w,':',ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programers : program\n",
      "program : program\n",
      "with : with\n",
      "programing : program\n",
      "langauage : langauag\n"
     ]
    }
   ],
   "source": [
    "#stemming of sentence\n",
    "from nltk.tokenize import word_tokenize\n",
    "ps = PorterStemmer()\n",
    "sentence = \"Programers program with programing langauage\"\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "for w in words:\n",
    "    print(w,':',ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : better\n",
      "worst : bad\n"
     ]
    }
   ],
   "source": [
    "#Lemmitization of word \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print('rocks :',lemmatizer.lemmatize('rocks'))\n",
    "print('corpora :',lemmatizer.lemmatize('corpora'))\n",
    "\n",
    "#a denotes adjective in 'pos'\n",
    "print('better :',lemmatizer.lemmatize('better',pos = 'n'))\n",
    "print('worst :',lemmatizer.lemmatize('worst',pos = 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bat\n",
      "are\n",
      "foot\n",
      "child\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "#Init the Wordnet Lemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Lemmatize Single Word\n",
    "print(lemmatizer.lemmatize('bats'))\n",
    "print(lemmatizer.lemmatize('are'))\n",
    "print(lemmatizer.lemmatize('feet'))\n",
    "print(lemmatizer.lemmatize('children'))\n",
    "print(lemmatizer.lemmatize('data'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best'] \n",
      "\n",
      "The striped bat are hanging on their foot for best\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#define the sentence to be lemmatized\n",
    "sentence = 'The striped bats are  hanging on their feet for best'\n",
    "\n",
    "# Tokenize : split the sentence into  words\n",
    "word_list = nltk.word_tokenize(sentence)\n",
    "print(word_list,'\\n')\n",
    "\n",
    "#Lemmatize list of words and join\n",
    "lemmatized_output =' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "print(lemmatized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('feet', 'UNK')]\n",
      "[('The', 'DT'), ('striped', 'JJ'), ('bats', 'NNS'), ('are', 'VBP'), ('hanging', 'VBG'), ('on', 'IN'), ('their', 'PRP$'), ('feet', 'NNS'), ('for', 'IN'), ('best', 'JJS')]\n"
     ]
    }
   ],
   "source": [
    "#wordnet lemmatizer with appropraite POS tag\n",
    "print(nltk.pos_tag(['feet'],'\\n'))\n",
    "\n",
    "print(nltk.pos_tag(nltk.word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus 1\\Anaconda3\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.479642481898331\n"
     ]
    }
   ],
   "source": [
    "#NLP document similarity\n",
    "\n",
    "#if this spacy is not running in your notebook then use google colab\n",
    "#pip install spacy\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp =spacy.load('en_core_web_sm')\n",
    "doc1 = nlp(u'Hello hi there!')\n",
    "doc2 = nlp(u'Hello hi there!')\n",
    "doc3 = nlp(u'Hey whatsup')\n",
    "\n",
    "print(doc1.similarity(doc1))\n",
    "print(doc1.similarity(doc2))\n",
    "print(doc1.similarity(doc3))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import models\n",
    "import numpy as np\n",
    "\n",
    "document = ['This is the first line','This is the second sentence','This is third document third']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'the', 'first', 'line'], ['this', 'is', 'the', 'second', 'sentence'], ['this', 'is', 'third', 'document', 'third']]\n"
     ]
    }
   ],
   "source": [
    "#Tokenize using nltk module\n",
    "from nltk .tokenize import word_tokenize\n",
    "gen_docs = [[w.lower() for w in word_tokenize(text)] for text  in document]\n",
    "print(gen_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first': 0,\n",
       " 'is': 1,\n",
       " 'line': 2,\n",
       " 'the': 3,\n",
       " 'this': 4,\n",
       " 'second': 5,\n",
       " 'sentence': 6,\n",
       " 'document': 7,\n",
       " 'third': 8}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary =gensim.corpora.Dictionary(gen_docs)\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)], [(1, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(1, 1), (4, 1), (7, 1), (8, 2)]]\n",
      "[['this', 'is', 'the', 'first', 'line'], ['this', 'is', 'the', 'second', 'sentence'], ['this', 'is', 'third', 'document', 'third']]\n"
     ]
    }
   ],
   "source": [
    "#dictionary.token2id\n",
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "print(corpus)\n",
    "print(gen_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['first', 0.68], ['line', 0.68], ['the', 0.25]]\n",
      "[['the', 0.25], ['second', 0.68], ['sentence', 0.68]]\n",
      "[['document', 0.45], ['third', 0.89]]\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus)\n",
    "#show the TF-IDF weights\n",
    "\n",
    "mydict = dictionary\n",
    "for  doc in tfidf[corpus]:\n",
    "    print([[mydict[id],np.around(freq,decimals= 2)]for id, freq in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deifne the documents \n",
    "doc_trump = 'Mr Trump became president after winning the polotical election Through the support'\n",
    "doc_election = 'President Trump says Putin had no political interference is the election outcome'\n",
    "doc_putin ='Post Election,Valdamir Putin became President of Russia. President Putin had served'\n",
    "documents =[doc_trump,doc_election,doc_putin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Election,Valdamir Putin became President of Russia. President Putin had served\n"
     ]
    }
   ],
   "source": [
    "print(doc_putin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6)\t1\n",
      "  (0, 21)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 19)\t2\n",
      "  (0, 11)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 20)\t1\n",
      "  (0, 18)\t1\n",
      "  (1, 21)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 19)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 9)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 13)\t2\n",
      "  (2, 2)\t1\n",
      "  (2, 14)\t2\n",
      "  (2, 3)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 22)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 17)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "#create the document term matrix\n",
    "Count_Vectorizer = CountVectorizer(stop_words ='english')\n",
    "Count_Vectorizer = CountVectorizer()\n",
    "sparse_matrix = Count_Vectorizer.fit_transform(documents)\n",
    "print(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL : Convert SPARSE MATRIX TO PANDAS DATAFRAME  IF YOU\n",
    "doc_term_matrix =sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix,columns =Count_Vectorizer.get_feature_names(),index =['doc_trump','doc_election','doc_putin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after</th>\n",
       "      <th>became</th>\n",
       "      <th>election</th>\n",
       "      <th>had</th>\n",
       "      <th>interference</th>\n",
       "      <th>is</th>\n",
       "      <th>mr</th>\n",
       "      <th>no</th>\n",
       "      <th>of</th>\n",
       "      <th>outcome</th>\n",
       "      <th>...</th>\n",
       "      <th>putin</th>\n",
       "      <th>russia</th>\n",
       "      <th>says</th>\n",
       "      <th>served</th>\n",
       "      <th>support</th>\n",
       "      <th>the</th>\n",
       "      <th>through</th>\n",
       "      <th>trump</th>\n",
       "      <th>valdamir</th>\n",
       "      <th>winning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>doc_trump</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>doc_election</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>doc_putin</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              after  became  election  had  interference  is  mr  no  of  \\\n",
       "doc_trump         1       1         1    0             0   0   1   0   0   \n",
       "doc_election      0       0         1    1             1   1   0   1   0   \n",
       "doc_putin         0       1         1    1             0   0   0   0   1   \n",
       "\n",
       "              outcome  ...  putin  russia  says  served  support  the  \\\n",
       "doc_trump           0  ...      0       0     0       0        1    2   \n",
       "doc_election        1  ...      1       0     1       0        0    1   \n",
       "doc_putin           0  ...      2       1     0       1        0    0   \n",
       "\n",
       "              through  trump  valdamir  winning  \n",
       "doc_trump           1      1         0        1  \n",
       "doc_election        0      1         0        0  \n",
       "doc_putin           0      0         1        0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.38575837 0.26726124]\n",
      " [0.38575837 1.         0.4330127 ]\n",
      " [0.26726124 0.4330127  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df,df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deifne the documents \n",
    "doc_trump = 'Mr Trump became president after winning the political election Through the support'\n",
    "doc_election = 'President Trump says Putin had no political interference is the election outcome'\n",
    "doc_putin ='Post Election,Valdamir Putin became President of Russia. President Putin had served'\n",
    "doc_test = 'Post Election,Valdamir Alex became President of Russia. President ALex had served'\n",
    "documents =[doc_trump,doc_election,doc_putin,doc_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7)\t1\n",
      "  (0, 21)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 19)\t2\n",
      "  (0, 11)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 20)\t1\n",
      "  (0, 18)\t1\n",
      "  (1, 21)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 19)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 13)\t2\n",
      "  (2, 3)\t1\n",
      "  (2, 14)\t2\n",
      "  (2, 4)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 22)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 17)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 13)\t2\n",
      "  (3, 3)\t1\n",
      "  (3, 4)\t1\n",
      "  (3, 12)\t1\n",
      "  (3, 22)\t1\n",
      "  (3, 9)\t1\n",
      "  (3, 15)\t1\n",
      "  (3, 17)\t1\n",
      "  (3, 1)\t2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "#create the document term matrix\n",
    "Count_Vectorizer = CountVectorizer(stop_words ='english')\n",
    "Count_Vectorizer = CountVectorizer()\n",
    "sparse_matrix = Count_Vectorizer.fit_transform(documents)\n",
    "print(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL : Convert SPARSE MATRIX TO PANDAS DATAFRAME  IF YOU\n",
    "doc_term_matrix =sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix,columns =Count_Vectorizer.get_feature_names(),index =['doc_trump','doc_election','doc_putin','doc_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after</th>\n",
       "      <th>alex</th>\n",
       "      <th>became</th>\n",
       "      <th>election</th>\n",
       "      <th>had</th>\n",
       "      <th>interference</th>\n",
       "      <th>is</th>\n",
       "      <th>mr</th>\n",
       "      <th>no</th>\n",
       "      <th>of</th>\n",
       "      <th>...</th>\n",
       "      <th>putin</th>\n",
       "      <th>russia</th>\n",
       "      <th>says</th>\n",
       "      <th>served</th>\n",
       "      <th>support</th>\n",
       "      <th>the</th>\n",
       "      <th>through</th>\n",
       "      <th>trump</th>\n",
       "      <th>valdamir</th>\n",
       "      <th>winning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>doc_trump</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>doc_election</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>doc_putin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>doc_test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              after  alex  became  election  had  interference  is  mr  no  \\\n",
       "doc_trump         1     0       1         1    0             0   0   1   0   \n",
       "doc_election      0     0       0         1    1             1   1   0   1   \n",
       "doc_putin         0     0       1         1    1             0   0   0   0   \n",
       "doc_test          0     2       1         1    1             0   0   0   0   \n",
       "\n",
       "              of  ...  putin  russia  says  served  support  the  through  \\\n",
       "doc_trump      0  ...      0       0     0       0        1    2        1   \n",
       "doc_election   0  ...      1       0     1       0        0    1        0   \n",
       "doc_putin      1  ...      2       1     0       1        0    0        0   \n",
       "doc_test       1  ...      0       1     0       1        0    0        0   \n",
       "\n",
       "              trump  valdamir  winning  \n",
       "doc_trump         1         0        1  \n",
       "doc_election      1         0        0  \n",
       "doc_putin         0         1        0  \n",
       "doc_test          0         1        0  \n",
       "\n",
       "[4 rows x 24 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.46291005 0.26726124 0.26726124]\n",
      " [0.46291005 1.         0.4330127  0.28867513]\n",
      " [0.26726124 0.4330127  1.         0.75      ]\n",
      " [0.26726124 0.28867513 0.75       1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df,df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr Trump became president after winning the political election Through the support\n",
      "new out put is : Mr Trump became president winning political election Through support \n"
     ]
    }
   ],
   "source": [
    "#Removing Stop Words\n",
    "print(doc_trump)\n",
    "j = ''\n",
    "for x in doc_trump.split():\n",
    "    if x not in stop:\n",
    "        j = j+x+' '\n",
    "print('new out put is :',j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ramu', 'had', 'eggs', 'for', 'breakfast']\n",
      "['Today', 'it', 'is', 'sunny', 'out', 'side']\n",
      "5\n",
      "6\n",
      "27\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "doc1 = 'Ramu had eggs for breakfast'\n",
    "doc2 = 'Today it is sunny out side'\n",
    "\n",
    "print((doc1).split(' '))\n",
    "print((doc2).split(' '))\n",
    "\n",
    "print(len(str(doc1).split(' '))) # No of words\n",
    "print(len(str(doc2).split(' ')))\n",
    "\n",
    "print(len(doc1)) #No of Characters\n",
    "print(len(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#twitter = open('tweets_small01.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter.read() = twitter.read().apply(lambda x : len(str(x).split('')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>happy birth day your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user danny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr8 !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                       happy birth day your majesty\n",
       "3   4      0   #model   i love u take with u all the time in ur\n",
       "4   5      0             factsguide: society now    #motivation\n",
       "5   6      0  [2/2] huge fan fare and big talking before the...\n",
       "6   7      0                 @user camping tomorrow @user danny\n",
       "7   8      0  the next school year is the year for exams.can...\n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr8 !"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter = pd.read_csv('tweets_small01.txt')\n",
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count\n",
    "\n",
    "twitter['word_count'] = twitter['tweet'].apply(lambda x : len(str(x).split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>happy birth day your majesty</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user danny</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.can...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr8 !</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  word_count\n",
       "0   1      0   @user when a father is dysfunctional and is s...          20\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...          19\n",
       "2   3      0                       happy birth day your majesty           5\n",
       "3   4      0   #model   i love u take with u all the time in ur          14\n",
       "4   5      0             factsguide: society now    #motivation           8\n",
       "5   6      0  [2/2] huge fan fare and big talking before the...          19\n",
       "6   7      0                 @user camping tomorrow @user danny           6\n",
       "7   8      0  the next school year is the year for exams.can...          12\n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...          10\n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr8 !          14"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "#Number of character count\n",
    "doc3 = 'Hello how are you ?'\n",
    "print(len(doc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of stop words : 3\n"
     ]
    }
   ],
   "source": [
    "#count of stop words\n",
    "#y = 'you are a very good boy'\n",
    "\n",
    "y = 'i had toast for break fast'\n",
    "i = 0\n",
    "for x in y.split():\n",
    "    if x not in stop:\n",
    "        i+=1\n",
    "print('no of stop words :',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of stop words : 2\n"
     ]
    }
   ],
   "source": [
    "#count of stop words\n",
    "y = 'you are a very good boy'\n",
    "\n",
    "#y = 'i had toast for break fast'\n",
    "i = 0\n",
    "for x in y.split():\n",
    "    if x not in stop:\n",
    "        i+=1\n",
    "print('no of stop words :',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of special characters : 1\n"
     ]
    }
   ],
   "source": [
    "#no of special characters\n",
    "\n",
    "y = 'I am @home in Mumbai'\n",
    "i = 0\n",
    "for x in y.split():\n",
    "    if x.startswith('@'):\n",
    "        i+=1\n",
    "print('no of special characters :',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,label,tweet\n",
      "1,0, @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.  \n",
      "2,0,@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.  \n",
      "3,0,happy birth day your majesty\n",
      "4,0,#model   i love u take with u all the time in ur\n",
      "5,0, factsguide: society now    #motivation\n",
      "6,0,[2/2] huge fan fare and big talking before they leave. chaos and pay disputes when they get there \n",
      "7,0, @user camping tomorrow @user danny\n",
      "8,0,the next school year is the year for exams.can't think about that\n",
      "9,0,we won!!! love the land!!! #allin #cavs #champions #cleveland #clevelandcavaliers\n",
      "10,0, @user @user welcome here !  i'm   it's so #gr8 !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter2 = open('tweets_small01.txt', 'r')\n",
    "y = twitter2.read()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of special characters : 16\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for x in y:\n",
    "    if x.startswith('#') or x.startswith('@'):\n",
    "        i+=1\n",
    "print('no of special characters :',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of digits : 2\n"
     ]
    }
   ],
   "source": [
    "#no of digits\n",
    "y = 'I am @home 12 yrs old. my rollno is 505'\n",
    "i = 0\n",
    "for x in y.split():\n",
    "    if x.isdigit():\n",
    "        i+=1\n",
    "print('no of digits :',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of uppercase characters : 1\n"
     ]
    }
   ],
   "source": [
    "#no of upper characters\n",
    "\n",
    "y = 'I am @home 12 yrs old. my rollno is 505'\n",
    "i = 0\n",
    "for x in y.split():\n",
    "    if x.isupper():\n",
    "        i+=1\n",
    "print('no of uppercase characters :',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of uppercase characters : 3\n"
     ]
    }
   ],
   "source": [
    "#no of uppercase characters\n",
    "\n",
    "y = 'I am @home 12 yrs old. my ROLL NO is 505'\n",
    "i = 0\n",
    "for x in y.split():\n",
    "    if x.isupper():\n",
    "        i+=1\n",
    "print('no of uppercase characters :',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of characters starting with lowercase letters : 5\n"
     ]
    }
   ],
   "source": [
    "#no of lowercase characters\n",
    "\n",
    "y = 'I am @home 12 yrs old. my ROLL NO is 505'\n",
    "i = 0\n",
    "for x in y.split():\n",
    "    if x[0].islower():\n",
    "        i+=1\n",
    "print('no of characters starting with lowercase letters :',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence in LowerCase :  i live in pune and eat mango \n"
     ]
    }
   ],
   "source": [
    "#convert to lower case\n",
    "y = 'I live in Pune and Eat Mango'\n",
    "i = ' '\n",
    "for x in y.split():\n",
    "    i = i + x.lower() + ' '\n",
    "print('Sentence in LowerCase :',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we pune are 1 and 88 happy  people\n"
     ]
    }
   ],
   "source": [
    "#removing special characters\n",
    "\n",
    "import re\n",
    "y = 'we @pune are #1 &and 88 happy !! people.'\n",
    "y = re.sub(r'[^\\w\\s]','',y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower and stop Words Removed :  i  live  pune  eat  mango  \n"
     ]
    }
   ],
   "source": [
    "#convert text tolower and Remove stop words\n",
    "\n",
    "y = 'I live in Pune and Eat Mango'\n",
    "i = ' '\n",
    "\n",
    "for x in y.split():\n",
    "    if x not in stop:\n",
    "        i = (i+x+' ').lower() + ' '\n",
    "    \n",
    "print('lower and stop Words Removed :',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>happy birth day your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user danny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr8 !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                       happy birth day your majesty\n",
       "3   4      0   #model   i love u take with u all the time in ur\n",
       "4   5      0             factsguide: society now    #motivation\n",
       "5   6      0  [2/2] huge fan fare and big talking before the...\n",
       "6   7      0                 @user camping tomorrow @user danny\n",
       "7   8      0  the next school year is the year for exams.can...\n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr8 !"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter = pd.read_csv('tweets_small01.txt')\n",
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>happy birth day your majesty</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user danny</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.can...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr8 !</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  word_count\n",
       "0   1      0   @user when a father is dysfunctional and is s...          20\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...          19\n",
       "2   3      0                       happy birth day your majesty           5\n",
       "3   4      0   #model   i love u take with u all the time in ur          14\n",
       "4   5      0             factsguide: society now    #motivation           8\n",
       "5   6      0  [2/2] huge fan fare and big talking before the...          19\n",
       "6   7      0                 @user camping tomorrow @user danny           6\n",
       "7   8      0  the next school year is the year for exams.can...          12\n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...          10\n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr8 !          14"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word count\n",
    "\n",
    "twitter['word_count'] = twitter['tweet'].apply(lambda x : len(str(x).split(' ')))\n",
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sw': '@user father dysfunctional selfish drags kids dysfunction. '}\n",
      "{'sw': \"@user @user thanks #lyft credit can't use cause offer wheelchair vans pdx. \"}\n",
      "{'sw': 'happy birth day majesty '}\n",
      "{'sw': '#model love u take u time ur '}\n",
      "{'sw': 'factsguide: society #motivation '}\n",
      "{'sw': '[2/2] huge fan fare big talking leave. chaos pay disputes get '}\n",
      "{'sw': '@user camping tomorrow @user danny '}\n",
      "{'sw': \"next school year year exams.can't think \"}\n",
      "{'sw': 'won!!! love land!!! #allin #cavs #champions #cleveland #clevelandcavaliers '}\n",
      "{'sw': \"@user @user welcome ! i'm #gr8 ! \"}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "\n",
    "def st_w(j):\n",
    "    data = dict()\n",
    "    data['sw'] = j\n",
    "    print (data)\n",
    "    return data\n",
    "\n",
    "sw= pd.DataFrame([],columns = ['sw'])  \n",
    "for i in range(0,len(twitter['tweet'])):\n",
    "    j = '' \n",
    "    for x in twitter['tweet'][i].split():\n",
    "        if x not in stop:\n",
    "            j = j+x+' '\n",
    " #   print(j)    \n",
    "    sw= sw.append(st_w(j),ignore_index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@user father dysfunctional selfish drags kids ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@user @user thanks #lyft credit can't use caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>happy birth day majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>#model love u take u time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>factsguide: society #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[2/2] huge fan fare big talking leave. chaos p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>@user camping tomorrow @user danny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>next school year year exams.can't think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>won!!! love land!!! #allin #cavs #champions #c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>@user @user welcome ! i'm #gr8 !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sw\n",
       "0  @user father dysfunctional selfish drags kids ...\n",
       "1  @user @user thanks #lyft credit can't use caus...\n",
       "2                           happy birth day majesty \n",
       "3                      #model love u take u time ur \n",
       "4                   factsguide: society #motivation \n",
       "5  [2/2] huge fan fare big talking leave. chaos p...\n",
       "6                @user camping tomorrow @user danny \n",
       "7           next school year year exams.can't think \n",
       "8  won!!! love land!!! #allin #cavs #champions #c...\n",
       "9                  @user @user welcome ! i'm #gr8 ! "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>removed_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>20</td>\n",
       "      <td>@user father dysfunctional selfish drags kids ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>19</td>\n",
       "      <td>@user @user thanks #lyft credit can't use caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>happy birth day your majesty</td>\n",
       "      <td>5</td>\n",
       "      <td>happy birth day majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur</td>\n",
       "      <td>14</td>\n",
       "      <td>#model love u take u time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>8</td>\n",
       "      <td>factsguide: society #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>19</td>\n",
       "      <td>[2/2] huge fan fare big talking leave. chaos p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user danny</td>\n",
       "      <td>6</td>\n",
       "      <td>@user camping tomorrow @user danny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.can...</td>\n",
       "      <td>12</td>\n",
       "      <td>next school year year exams.can't think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>10</td>\n",
       "      <td>won!!! love land!!! #allin #cavs #champions #c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr8 !</td>\n",
       "      <td>14</td>\n",
       "      <td>@user @user welcome ! i'm #gr8 !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  word_count  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...          20   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...          19   \n",
       "2   3      0                       happy birth day your majesty           5   \n",
       "3   4      0   #model   i love u take with u all the time in ur          14   \n",
       "4   5      0             factsguide: society now    #motivation           8   \n",
       "5   6      0  [2/2] huge fan fare and big talking before the...          19   \n",
       "6   7      0                 @user camping tomorrow @user danny           6   \n",
       "7   8      0  the next school year is the year for exams.can...          12   \n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...          10   \n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr8 !          14   \n",
       "\n",
       "                                  removed_stop_words  \n",
       "0  @user father dysfunctional selfish drags kids ...  \n",
       "1  @user @user thanks #lyft credit can't use caus...  \n",
       "2                           happy birth day majesty   \n",
       "3                      #model love u take u time ur   \n",
       "4                   factsguide: society #motivation   \n",
       "5  [2/2] huge fan fare big talking leave. chaos p...  \n",
       "6                @user camping tomorrow @user danny   \n",
       "7           next school year year exams.can't think   \n",
       "8  won!!! love land!!! #allin #cavs #champions #c...  \n",
       "9                  @user @user welcome ! i'm #gr8 !   "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter['removed_stop_words'] = pd.Series(sw['sw'])\n",
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>removed_stop_words</th>\n",
       "      <th>r_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>20</td>\n",
       "      <td>@user father dysfunctional selfish drags kids ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>19</td>\n",
       "      <td>@user @user thanks #lyft credit can't use caus...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>happy birth day your majesty</td>\n",
       "      <td>5</td>\n",
       "      <td>happy birth day majesty</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur</td>\n",
       "      <td>14</td>\n",
       "      <td>#model love u take u time ur</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>8</td>\n",
       "      <td>factsguide: society #motivation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>19</td>\n",
       "      <td>[2/2] huge fan fare big talking leave. chaos p...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user danny</td>\n",
       "      <td>6</td>\n",
       "      <td>@user camping tomorrow @user danny</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.can...</td>\n",
       "      <td>12</td>\n",
       "      <td>next school year year exams.can't think</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>10</td>\n",
       "      <td>won!!! love land!!! #allin #cavs #champions #c...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr8 !</td>\n",
       "      <td>14</td>\n",
       "      <td>@user @user welcome ! i'm #gr8 !</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  word_count  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...          20   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...          19   \n",
       "2   3      0                       happy birth day your majesty           5   \n",
       "3   4      0   #model   i love u take with u all the time in ur          14   \n",
       "4   5      0             factsguide: society now    #motivation           8   \n",
       "5   6      0  [2/2] huge fan fare and big talking before the...          19   \n",
       "6   7      0                 @user camping tomorrow @user danny           6   \n",
       "7   8      0  the next school year is the year for exams.can...          12   \n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...          10   \n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr8 !          14   \n",
       "\n",
       "                                  removed_stop_words  r_word_count  \n",
       "0  @user father dysfunctional selfish drags kids ...             8  \n",
       "1  @user @user thanks #lyft credit can't use caus...            13  \n",
       "2                           happy birth day majesty              5  \n",
       "3                      #model love u take u time ur              8  \n",
       "4                   factsguide: society #motivation              4  \n",
       "5  [2/2] huge fan fare big talking leave. chaos p...            12  \n",
       "6                @user camping tomorrow @user danny              6  \n",
       "7           next school year year exams.can't think              7  \n",
       "8  won!!! love land!!! #allin #cavs #champions #c...             9  \n",
       "9                  @user @user welcome ! i'm #gr8 !              8  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter['r_word_count'] = twitter['removed_stop_words'].apply(lambda x : len(str(x).split(' ')))\n",
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>removed_stop_words</th>\n",
       "      <th>r_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>20</td>\n",
       "      <td>@user father dysfunctional selfish drags kids ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>19</td>\n",
       "      <td>@user @user thanks #lyft credit can't use caus...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>happy birth day your majesty</td>\n",
       "      <td>5</td>\n",
       "      <td>happy birth day majesty</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur</td>\n",
       "      <td>14</td>\n",
       "      <td>#model love u take u time ur</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>8</td>\n",
       "      <td>factsguide: society #motivation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>19</td>\n",
       "      <td>[2/2] huge fan fare big talking leave. chaos p...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user danny</td>\n",
       "      <td>6</td>\n",
       "      <td>@user camping tomorrow @user danny</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.can...</td>\n",
       "      <td>12</td>\n",
       "      <td>next school year year exams.can't think</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>10</td>\n",
       "      <td>won!!! love land!!! #allin #cavs #champions #c...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr8 !</td>\n",
       "      <td>14</td>\n",
       "      <td>@user @user welcome ! i'm #gr8 !</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  word_count  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...          20   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...          19   \n",
       "2   3      0                       happy birth day your majesty           5   \n",
       "3   4      0   #model   i love u take with u all the time in ur          14   \n",
       "4   5      0             factsguide: society now    #motivation           8   \n",
       "5   6      0  [2/2] huge fan fare and big talking before the...          19   \n",
       "6   7      0                 @user camping tomorrow @user danny           6   \n",
       "7   8      0  the next school year is the year for exams.can...          12   \n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...          10   \n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr8 !          14   \n",
       "\n",
       "                                  removed_stop_words  r_word_count  \n",
       "0  @user father dysfunctional selfish drags kids ...             8  \n",
       "1  @user @user thanks #lyft credit can't use caus...            13  \n",
       "2                           happy birth day majesty              5  \n",
       "3                      #model love u take u time ur              8  \n",
       "4                   factsguide: society #motivation              4  \n",
       "5  [2/2] huge fan fare big talking leave. chaos p...            12  \n",
       "6                @user camping tomorrow @user danny              6  \n",
       "7           next school year year exams.can't think              7  \n",
       "8  won!!! love land!!! #allin #cavs #champions #c...             9  \n",
       "9                  @user @user welcome ! i'm #gr8 !              8  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>removed_stop_words</th>\n",
       "      <th>r_word_count</th>\n",
       "      <th>remove_special_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>20</td>\n",
       "      <td>@user father dysfunctional selfish drags kids ...</td>\n",
       "      <td>8</td>\n",
       "      <td>user father dysfunctional selfish drags kids d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>19</td>\n",
       "      <td>@user @user thanks #lyft credit can't use caus...</td>\n",
       "      <td>13</td>\n",
       "      <td>user user thanks lyft credit cant use cause of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>happy birth day your majesty</td>\n",
       "      <td>5</td>\n",
       "      <td>happy birth day majesty</td>\n",
       "      <td>5</td>\n",
       "      <td>happy birth day majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur</td>\n",
       "      <td>14</td>\n",
       "      <td>#model love u take u time ur</td>\n",
       "      <td>8</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>8</td>\n",
       "      <td>factsguide: society #motivation</td>\n",
       "      <td>4</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>19</td>\n",
       "      <td>[2/2] huge fan fare big talking leave. chaos p...</td>\n",
       "      <td>12</td>\n",
       "      <td>22 huge fan fare big talking leave chaos pay d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user danny</td>\n",
       "      <td>6</td>\n",
       "      <td>@user camping tomorrow @user danny</td>\n",
       "      <td>6</td>\n",
       "      <td>user camping tomorrow user danny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.can...</td>\n",
       "      <td>12</td>\n",
       "      <td>next school year year exams.can't think</td>\n",
       "      <td>7</td>\n",
       "      <td>next school year year examscant think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>10</td>\n",
       "      <td>won!!! love land!!! #allin #cavs #champions #c...</td>\n",
       "      <td>9</td>\n",
       "      <td>won love land allin cavs champions cleveland c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr8 !</td>\n",
       "      <td>14</td>\n",
       "      <td>@user @user welcome ! i'm #gr8 !</td>\n",
       "      <td>8</td>\n",
       "      <td>user user welcome  im gr8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  word_count  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...          20   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...          19   \n",
       "2   3      0                       happy birth day your majesty           5   \n",
       "3   4      0   #model   i love u take with u all the time in ur          14   \n",
       "4   5      0             factsguide: society now    #motivation           8   \n",
       "5   6      0  [2/2] huge fan fare and big talking before the...          19   \n",
       "6   7      0                 @user camping tomorrow @user danny           6   \n",
       "7   8      0  the next school year is the year for exams.can...          12   \n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...          10   \n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr8 !          14   \n",
       "\n",
       "                                  removed_stop_words  r_word_count  \\\n",
       "0  @user father dysfunctional selfish drags kids ...             8   \n",
       "1  @user @user thanks #lyft credit can't use caus...            13   \n",
       "2                           happy birth day majesty              5   \n",
       "3                      #model love u take u time ur              8   \n",
       "4                   factsguide: society #motivation              4   \n",
       "5  [2/2] huge fan fare big talking leave. chaos p...            12   \n",
       "6                @user camping tomorrow @user danny              6   \n",
       "7           next school year year exams.can't think              7   \n",
       "8  won!!! love land!!! #allin #cavs #champions #c...             9   \n",
       "9                  @user @user welcome ! i'm #gr8 !              8   \n",
       "\n",
       "                                 remove_special_char  \n",
       "0  user father dysfunctional selfish drags kids d...  \n",
       "1  user user thanks lyft credit cant use cause of...  \n",
       "2                           happy birth day majesty   \n",
       "3                       model love u take u time ur   \n",
       "4                     factsguide society motivation   \n",
       "5  22 huge fan fare big talking leave chaos pay d...  \n",
       "6                  user camping tomorrow user danny   \n",
       "7             next school year year examscant think   \n",
       "8  won love land allin cavs champions cleveland c...  \n",
       "9                        user user welcome  im gr8    "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing special characters\n",
    "\n",
    "import re\n",
    "#y = 'we @pune are #1 &and 88 happy !! people.'\n",
    "#y = re.sub(r'[^\\w\\s]','',y)\n",
    "#print(y)\n",
    "\n",
    "twitter['remove_special_char'] = twitter['removed_stop_words'].apply(lambda x : re.sub(r'[^\\w\\s]','',x))\n",
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
